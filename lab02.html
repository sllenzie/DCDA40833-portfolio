<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Evaluation | Stella Lenzie</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <header>
        <nav>
            <a href="index.html">Home</a>
            <a href="lab02.html" class="active">Lab 2: AI Evaluation</a>
            <!-- Add more lab links as the semester progresses -->
        </nav>
        <h1>AI Tool Evaluation: Same Prompt, Different Results</h1>
    </header>

    <main>
        <section>
            <h2>Introduction</h2>
            <p>First of all, this software is neither artificial, nor intelligent. There seems to be the misconception that AI can invent whatever you’re telling it, but what it is really doing is using a lot of data to try to fill in the blanks as best as likely possible for what you are asking of it. This lends itself particularly well when the user has an image in their head, or the vague idea of one, and is looking to generate an image that gets as close as possible to the desired outcome. This is what I decided to explore in this lab, was the image generation capabilities of various tools, where I gave them similar prompts and was searching for a similar image. Here, I’ll compare the style of art that each model generated, the overall quality of the image produced, and how closely it resembles something that the viewer might think immediately was generated by AI.</p>
            <p>As for the image that I want to be produced, I’m looking for a colonial-style house with white trim, red shutters, a black door, and a well-landscaped front yard. The three tools that I decided to utilize were Google Gemini’s NanoBanana, Venice.ai, and Leonardo.ai. The prompt given to all three was exactly as stated above, and proved to be a good baseline for all three models.</p>
        </section>

        <section>
            <h2>Tool 1: Google Gemini’s NanoBanana</h2>
            <p>It thought for a few seconds, before producing a fairly accurate image to what I had in mind. It got the shutters correct, the general style correct, and the black front door was in place. It added the distinctly colonial columns and overhang to the front of the house, which was a good move, and added a porch to the right side. Overall, not bad, though the image appears a bit tilted, and I did not want the exterior to be exposed brick.</p>
            
            <figure>
                <img src="images/banana1.png" alt="Screenshot of image generated by Google Gemini’s NanoBanana" width="100%">
                <figcaption>First image generated by Google Gemini’s NanoBanana based on the prompt.</figcaption>
            </figure>

            <p>I then specified as such, and received a second iteration. It took care of the exterior color of the bricks, but missed the part about seeing more of the landscaping. However, the overall image is still quite life-like and doesn’t have the immediate AI smoothing that seems to be so prevalent.</p>

            <figure>
                <img src="images/banana2.png" alt="Screenshot of second image generated by Google Gemini’s NanoBanana" width="100%">
                <figcaption>Second image generated by Google Gemini’s NanoBanana after specifying exterior color.</figcaption>
            </figure>

            <p>The third iteration was where we started to go off the rails a little bit. I asked to pull back the view, to see more of the landscaping, and I don’t think it was as successful. It kept the red shutters, black door, and white walls as before, but it added a chimney which was in red brick, and there is a window missing on the roof of the house. As we continued refining the generation, the tell-tale signs of AI became more overt, where there were more issues that arise.</p>

            <figure>
                <img src="images/banana3.png" alt="Screenshot of third image generated by Google Gemini’s NanoBanana" width="100%"> 
                <figcaption>Third image generated by Google Gemini’s NanoBanana after requesting more landscaping.</figcaption>
            </figure>

        </section>

        <section>
            <h2>Tool 2: Venice.AI</h2>
            
            <p>For fairness, I did three generations from each model, using the final generated image as the end product. Next, was the generation from Venice.ai, where the initial prompt was the exact same as before.</p>

            <figure>
                <img src="images/venice1.png" alt="Screenshot of image generated by Venice.ai" width="100%">
                <figcaption>First image generated by Venice.ai based on the prompt.</figcaption>
            </figure>

            <p>Immediately, there are a few issues. It did not implement the red shutters that were specified, and there is a sort of haze over the whole image that is distinctly artificial. I made some additional comments, but the second iteration was horrible.</p>

            <figure>
                <img src="images/venice2.png" alt="Screenshot of second image generated by Venice.ai" width="100%">
                <figcaption>Second image generated by Venice.ai after additional comments.</figcaption>
            </figure>

            <p>It focused entirely too much on the red, but did not recall the original prompt. The landscaping is drab, there are entirely too many windows, the house is not symmetrical, there are a slew of issues. The haze is gone, but it lost sight of everything else that I asked of it, and focused on the first thing I mentioned instead.</p>

            <figure>
                <img src="images/venice3.png" alt="Screenshot of third image generated by Venice.ai" width="100%">
                <figcaption>Third image generated by Venice.ai after further refinement.</figcaption>
            </figure>

            <p>I find it really interesting that so far, both models’ final versions have included hydrangeas, though I mentioned them at no point during this process. This is much closer to what I had in mind originally, with technically all three points that I asked for being included. Overall, it still looks AI generated, but it is a lot closer than the original baseline.</p>

        </section>

        <section>
            <h2>Tool 3: Leonardo.AI</h2>
            <p>Finally, we have Leonardo.ai. I was a little put out that I needed to create a separate account for the third model, and it seemed that each iteration that I presented went against an alloted amount of tokens, and I would need to purchase more in order to continue refining the images or to access better models. From a business standpoint, it makes perfect sense, but from a user standpoint, I was miffed.</p>

            <figure>
                <img src="images/leonardo1.png" alt="Screenshot of image generated by Leonardo.ai" width="100%">
                <figcaption>First image generated by Leonardo.ai based on the prompt.</figcaption>
            </figure>

            <p>This iteration is the closest we’ve gotten to what I had in mind upon the first version. It has the shutters, the door, and the general style of the house, with accurate windows, and a correct-seeming era, even symmetrical landscaping. Really, that is the only qualm I have with this is that the landscaping leaves some to be desired. </p>

            <figure>
                <img src="images/leonardo2.png" alt="Screenshot of second image generated by Leonardo.ai" width="100%">
                <figcaption>Second image generated by Leonardo.ai after refinement.</figcaption>
            </figure>

            <p>The second iteration has the better landscaping that I asked for, and it ended up adding some columns over the front porch, but I was looking for a little more curb appeal. Again, this was really close, but fair is fair and I needed to generate another image.</p>

            <figure>
                <img src="images/leonardo3.png" alt="Screenshot of third image generated by Leonardo.ai" width="100%">
                <figcaption>Third image generated by Leonardo.ai after final adjustments.</figcaption>
            </figure>

            <p>Of the three from Leonardo, this is the image that looks the most “AI” and off-putting. The windows are too close together, the roof over the front door is Grecian at best, and the landscaping is still dull.</p>

        </section>

        <section>
            <h2>Overall Reflection</h2>
            <p>This was a good litmus test for the three different models, using the exact same prompt and trying to refine it in some manner or other. They all tried their best to churn out something that I would be happy with, and were mostly successful. There seemed to be a trend that the further I went into the image generation process, the more that the images would lose their specific identifying features and take on the trademark “AI look” more and more. This type of image generation could greatly affect designers, artists, and the like, but it would be a good tool for smaller projects that just needed a better inspiration board or the like. These images are leaps and bounds ahead of where AI was even a year ago, not to mention even further. But, I think it is better to use multiple tools and not rely on one or two in order to keep the market competitive and try our best to protect against a monopoly.</p>
        </section>
    </main>

    <footer>
        <p>&copy; 2026 Stella Lenzie | <a href="https://github.com/sllenzie/DCDA40833-portfolio">GitHub</a></p>
    </footer>
</body>
</html>